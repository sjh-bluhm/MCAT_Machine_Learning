{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e1a9c-203d-47f3-9374-06c0a820addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "#Python >= 3.5\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "#Scikit-Learn >= 0.20\n",
    "import sklearn as sk\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "#numpy for calculations\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#matplotlib for figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#a magic function that allows inline plotting so figures are rendered in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#pandas for ...\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#add other needed modules here\n",
    "#Tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e73ee9-5e9e-4554-bc21-ea8bffbbc7d9",
   "metadata": {},
   "source": [
    "## Setup and Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d2f37-ec9d-4fad-94db-012c6dbdd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from the cv file using pandas\n",
    "scores = ...\n",
    "\n",
    "# drop irrelevant columns\n",
    "\n",
    "# sanity check: take a look at the data\n",
    "print('Scores data shape:', scores.shape)\n",
    "\n",
    "# preview first five lines\n",
    "scores.head()\n",
    "\n",
    "# print number of columns, column labels, column data types, memory usage, range index, and non-null number of cells in each column\n",
    "scores.info()\n",
    "\n",
    "# look at distribution of scores\n",
    "scores['Real Score'].value_counts()\n",
    "\n",
    "# gives count, mean, standard deviation, min, max, and percentiles (including median)\n",
    "scores.describe(percentiles = [0.25, 0.5, 0.75], include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87aa63d-22f2-4676-89c7-8df143b08b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some data statistics for the report\n",
    "# for report: (state the number of datapoints, briefly describe the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42831d28-12cf-4493-b7d9-e9e0ab74b3a4",
   "metadata": {},
   "source": [
    "## Visualize and Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368028e-694d-41d8-bd58-d46b8816a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "# look at how many values are missing in each dataframe column\n",
    "missing_values_table(scores)\n",
    "\n",
    "# visualize missing data with Missingno\n",
    "msno.bar(scores)\n",
    "msno.matrix(scores)\n",
    "\n",
    "# see if there is a reason for missing data\n",
    "msno.heatmap(scores)\n",
    "msno.dendrogram(scores)\n",
    "\n",
    "# for linear regression, drop all rows with missing values\n",
    "scores.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41faa40-0247-4146-b3cb-b65297f108e8",
   "metadata": {},
   "source": [
    "## Clean Data and Add New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afd70c-e0fd-4f88-a3ea-2fe8a9ddb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with # negative values\n",
    "#                # days before exam > 180\n",
    "#                # exact duplicate values to another row\n",
    "#                # impossible scores (>528 total or >132 on any subsection)\n",
    "\n",
    "# add custom attribute: variance between test scores (if multiple test scores)\n",
    "# NOTE: make sure variance is calculated between different tests, not between subsections of the same test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30b3f4-015e-409d-a994-e98324158585",
   "metadata": {},
   "source": [
    "## Create a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23205a-8aa0-46e7-b0ee-0eca9c83688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features and labels from the observations\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0ebbe-e6cf-4cca-a9fe-3eb094a38c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split data into training and testing, fix random_state so output is the same every run\n",
    "train, test = train_test_split(X, y, shuffle=True,\n",
    "                                   test_size=..., random_state=0)\n",
    "\n",
    "#sanity check: look at how many data points are in train/test\n",
    "len(train_set)\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af13b459-b7e4-4d80-b906-a28455a1334e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#sanity check: preview test and training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      3\u001b[0m test_set\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "#sanity check: preview test and training data\n",
    "train_set.head()\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd3985-d8ec-46e6-986b-2ccd58ea7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import StratifiedShuffleSplit\n",
    "\n",
    "#perform stratified shufflesplit cross-validator\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\n",
    "#compares random and stratified error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d45b6b-5fc9-4a90-a653-6f533416cb21",
   "metadata": {},
   "source": [
    "## Visualize Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213876c-f1d2-48d3-a7f9-afbec1c4fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a correlation matrix with pandas\n",
    "corr_matrix[\"Real Score\"].sort_values(ascending=False)\n",
    "\n",
    "# create scatter matrices displaying totals, medians.\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"Real Score\", ..., ..., ...]\n",
    "scatter_matrix(scores[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0286b-13b6-4921-a85b-a444d2d9d2c7",
   "metadata": {},
   "source": [
    "## PCA to Create Linear Combinations of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60143afd-30bd-4e9c-b54f-16f0dbac2cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8dd3d7f-2eb1-4a9d-a750-d70fb1937656",
   "metadata": {},
   "source": [
    "# Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9dde2b-ecb0-4188-aece-a5f3d5133630",
   "metadata": {},
   "source": [
    "## Training and Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0a86f-9ca3-4a6b-91e1-a1e4d85a1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# initialize a linear regression object\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(\"DATA\", \"LABELS\")\n",
    "\n",
    "# sanity check: test out predictions and compare to labels\n",
    "print(lin_reg.predict(\"SOME DATA\"))\n",
    "print(list(\"SOME LABELS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22003fb7-b472-48ea-a212-43d1f5b4a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MCAT_predictions = lin_reg.predict(\"DATA\")\n",
    "lin_rmse = mean_squared_error(\"LABELS\", MCAT_predictions, squared=False)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971bf4d-76e4-4070-92b6-ba2c734d1847",
   "metadata": {},
   "source": [
    "## Further Evaluation with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee1601-8cdc-4a7a-9596-eee6bbc3f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, \"DATA\", \"LABELS\",\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
