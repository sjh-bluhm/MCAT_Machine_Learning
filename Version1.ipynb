{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136e1a9c-203d-47f3-9374-06c0a820addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "#Python >= 3.5\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "#Scikit-Learn >= 0.20\n",
    "import sklearn as sk\n",
    "assert sk.__version__ >= \"0.20\"\n",
    "\n",
    "#???\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#numpy for calculations\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#matplotlib for figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#a magic function that allows inline plotting so figures are rendered in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#pandas for ...\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#add other needed modules here\n",
    "#Tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e73ee9-5e9e-4554-bc21-ea8bffbbc7d9",
   "metadata": {},
   "source": [
    "## Setup and Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402f17a9-5cc1-4ba1-af7c-a1380e97cf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPROJECT_ROOT_DIR = \".\"\\nCHAPTER_ID = \"end_to_end_project\"\\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\\nos.makedirs(IMAGES_PATH, exist_ok=True)\\n\\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\\n    print(\"Saving figure\", fig_id)\\n    if tight_layout:\\n        plt.tight_layout()\\n    plt.savefig(path, format=fig_extension, dpi=resolution)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define where to save figures for this project\n",
    "\"\"\"\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89d2f37-ec9d-4fad-94db-012c6dbdd4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4996 entries, 0 to 4995\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Timestamp           4676 non-null   object \n",
      " 1   Exam Date           4301 non-null   object \n",
      " 2   Real Score          4948 non-null   float64\n",
      " 3   C/P Score           4947 non-null   float64\n",
      " 4   CARS Score          4947 non-null   float64\n",
      " 5   B/B Score           4947 non-null   float64\n",
      " 6   P/S Score           4947 non-null   float64\n",
      " 7   Days Before Exam    1733 non-null   float64\n",
      " 8   Total Score         1750 non-null   float64\n",
      " 9   C/P Score.1         1502 non-null   float64\n",
      " 10  CARS Score.1        1498 non-null   float64\n",
      " 11  B/B Score.1         1496 non-null   float64\n",
      " 12  P/S Score.1         1496 non-null   float64\n",
      " 13  Days Before Exam.1  2567 non-null   float64\n",
      " 14  Total Score.1       2633 non-null   float64\n",
      " 15  C/P Score.2         2330 non-null   float64\n",
      " 16  CARS Score.2        2329 non-null   float64\n",
      " 17  B/B Score.2         2327 non-null   float64\n",
      " 18  P/S Score.2         2331 non-null   float64\n",
      " 19  Days Before Exam.2  3303 non-null   object \n",
      " 20  Total Score.2       3408 non-null   float64\n",
      " 21  C/P Score.3         3044 non-null   float64\n",
      " 22  CARS Score.3        3043 non-null   float64\n",
      " 23  B/B Score.3         3042 non-null   float64\n",
      " 24  P/S Score.3         3042 non-null   float64\n",
      " 25  Exam Before Exam    3340 non-null   object \n",
      " 26  Total Score.3       4000 non-null   object \n",
      " 27  C/P Score.4         3544 non-null   object \n",
      " 28  CARS Score.4        3543 non-null   object \n",
      " 29  B/B Score.4         3541 non-null   object \n",
      " 30  P/S Score.4         3544 non-null   object \n",
      "dtypes: float64(22), object(9)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Exam Date</th>\n",
       "      <th>Real Score</th>\n",
       "      <th>C/P Score</th>\n",
       "      <th>CARS Score</th>\n",
       "      <th>B/B Score</th>\n",
       "      <th>P/S Score</th>\n",
       "      <th>Days Before Exam</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>C/P Score.1</th>\n",
       "      <th>...</th>\n",
       "      <th>C/P Score.3</th>\n",
       "      <th>CARS Score.3</th>\n",
       "      <th>B/B Score.3</th>\n",
       "      <th>P/S Score.3</th>\n",
       "      <th>Exam Before Exam</th>\n",
       "      <th>Total Score.3</th>\n",
       "      <th>C/P Score.4</th>\n",
       "      <th>CARS Score.4</th>\n",
       "      <th>B/B Score.4</th>\n",
       "      <th>P/S Score.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4676</td>\n",
       "      <td>4301</td>\n",
       "      <td>4948.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>1733.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1502.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>3043.000000</td>\n",
       "      <td>3042.000000</td>\n",
       "      <td>3042.000000</td>\n",
       "      <td>3340</td>\n",
       "      <td>4000</td>\n",
       "      <td>3544</td>\n",
       "      <td>3543</td>\n",
       "      <td>3541</td>\n",
       "      <td>3544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4650</td>\n",
       "      <td>342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242</td>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>9/20/16</td>\n",
       "      <td>1/28/17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>515</td>\n",
       "      <td>130</td>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269</td>\n",
       "      <td>272</td>\n",
       "      <td>676</td>\n",
       "      <td>799</td>\n",
       "      <td>796</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>515.914511</td>\n",
       "      <td>128.947847</td>\n",
       "      <td>128.163331</td>\n",
       "      <td>129.123711</td>\n",
       "      <td>129.598949</td>\n",
       "      <td>8.417773</td>\n",
       "      <td>515.797714</td>\n",
       "      <td>129.312250</td>\n",
       "      <td>...</td>\n",
       "      <td>128.729632</td>\n",
       "      <td>128.400920</td>\n",
       "      <td>128.880342</td>\n",
       "      <td>127.856673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.805011</td>\n",
       "      <td>6.247823</td>\n",
       "      <td>6.283536</td>\n",
       "      <td>6.259038</td>\n",
       "      <td>6.196021</td>\n",
       "      <td>16.390119</td>\n",
       "      <td>6.227275</td>\n",
       "      <td>1.996091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.988670</td>\n",
       "      <td>2.358199</td>\n",
       "      <td>1.905568</td>\n",
       "      <td>1.745526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2115.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp Exam Date   Real Score    C/P Score   CARS Score  \\\n",
       "count       4676      4301  4948.000000  4947.000000  4947.000000   \n",
       "unique      4650       342          NaN          NaN          NaN   \n",
       "top      9/20/16   1/28/17          NaN          NaN          NaN   \n",
       "freq          14        77          NaN          NaN          NaN   \n",
       "mean         NaN       NaN   515.914511   128.947847   128.163331   \n",
       "std          NaN       NaN    23.805011     6.247823     6.283536   \n",
       "min          NaN       NaN   417.000000    30.000000    29.000000   \n",
       "25%          NaN       NaN   512.000000   128.000000   127.000000   \n",
       "50%          NaN       NaN   517.000000   129.000000   128.000000   \n",
       "75%          NaN       NaN   520.000000   130.000000   130.000000   \n",
       "max          NaN       NaN  2115.000000   528.000000   528.000000   \n",
       "\n",
       "          B/B Score    P/S Score  Days Before Exam  Total Score  C/P Score.1  \\\n",
       "count   4947.000000  4947.000000       1733.000000  1750.000000  1502.000000   \n",
       "unique          NaN          NaN               NaN          NaN          NaN   \n",
       "top             NaN          NaN               NaN          NaN          NaN   \n",
       "freq            NaN          NaN               NaN          NaN          NaN   \n",
       "mean     129.123711   129.598949          8.417773   515.797714   129.312250   \n",
       "std        6.259038     6.196021         16.390119     6.227275     1.996091   \n",
       "min       30.000000    29.000000          0.000000   490.000000   120.000000   \n",
       "25%      128.000000   128.000000          4.000000   512.000000   128.000000   \n",
       "50%      129.000000   130.000000          6.000000   517.000000   130.000000   \n",
       "75%      131.000000   131.000000          7.000000   520.000000   131.000000   \n",
       "max      530.000000   529.000000        365.000000   528.000000   132.000000   \n",
       "\n",
       "        ...  C/P Score.3  CARS Score.3  B/B Score.3  P/S Score.3  \\\n",
       "count   ...  3044.000000   3043.000000  3042.000000  3042.000000   \n",
       "unique  ...          NaN           NaN          NaN          NaN   \n",
       "top     ...          NaN           NaN          NaN          NaN   \n",
       "freq    ...          NaN           NaN          NaN          NaN   \n",
       "mean    ...   128.729632    128.400920   128.880342   127.856673   \n",
       "std     ...     1.988670      2.358199     1.905568     1.745526   \n",
       "min     ...   118.000000    118.000000   118.000000   118.000000   \n",
       "25%     ...   127.000000    127.000000   128.000000   127.000000   \n",
       "50%     ...   129.000000    129.000000   129.000000   128.000000   \n",
       "75%     ...   130.000000    130.000000   130.000000   129.000000   \n",
       "max     ...   132.000000    132.000000   132.000000   132.000000   \n",
       "\n",
       "        Exam Before Exam  Total Score.3  C/P Score.4  CARS Score.4  \\\n",
       "count               3340           4000         3544          3543   \n",
       "unique               242             49           17            17   \n",
       "top                   28            515          130           128   \n",
       "freq                 269            272          676           799   \n",
       "mean                 NaN            NaN          NaN           NaN   \n",
       "std                  NaN            NaN          NaN           NaN   \n",
       "min                  NaN            NaN          NaN           NaN   \n",
       "25%                  NaN            NaN          NaN           NaN   \n",
       "50%                  NaN            NaN          NaN           NaN   \n",
       "75%                  NaN            NaN          NaN           NaN   \n",
       "max                  NaN            NaN          NaN           NaN   \n",
       "\n",
       "        B/B Score.4 P/S Score.4  \n",
       "count          3541        3544  \n",
       "unique           18          18  \n",
       "top             130         129  \n",
       "freq            796         812  \n",
       "mean            NaN         NaN  \n",
       "std             NaN         NaN  \n",
       "min             NaN         NaN  \n",
       "25%             NaN         NaN  \n",
       "50%             NaN         NaN  \n",
       "75%             NaN         NaN  \n",
       "max             NaN         NaN  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a function to load data from the cv file using pandas\n",
    "#convert to tensors??? how many dimensions? how many tensors/matrices/vectors?\n",
    "\n",
    "#call function and store dataframe\n",
    "scores = pd.read_csv(\"MCAT_Data.csv\", header=1)\n",
    "#dataTest = pd.read_csv(\"csv_tests.csv\", header=1,usecols=range(6,18))\n",
    "\n",
    "#sanity check: take a look at the data\n",
    "#preview first five lines\n",
    "scores.head()\n",
    "#print number of columns, column labels, column data types, memory usage, range index, and non-null number of cells in each column\n",
    "scores.info()\n",
    "#gives count, mean, standard deviation, min, max, and percentiles (including median)\n",
    "scores.describe(percentiles = [0.25, 0.5, 0.75], include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87aa63d-22f2-4676-89c7-8df143b08b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot some data statistics for the report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30b3f4-015e-409d-a994-e98324158585",
   "metadata": {},
   "source": [
    "## Creat a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23205a-8aa0-46e7-b0ee-0eca9c83688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a seed so the output is the same every run\n",
    "np.random.seed(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01d0ebbe-e6cf-4cca-a9fe-3eb094a38c83",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Days Before Exam0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m#Reshape them as a tensor of dimension : number of data points, number of blank exams, number of \"under exams\" + total score + days before exam \u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mblank_scores_tensor = blank_scores_array.reshape(blank_scores_array.shape[0],4,6)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     blank_scores \u001b[38;5;241m=\u001b[39m \u001b[43mblank_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDays Before Exam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#blank_scores = blank_scores.drop(columns=[\"Days Before Exam.1\"])\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#    i+=1\u001b[39;00m\n\u001b[1;32m     40\u001b[0m blank_scores\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Days Before Exam0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#split data into training and testing and save in variables\n",
    "#what is the best way to do that for our data set?\n",
    "#justification needed for Report 1\n",
    "#look at sklearn function train_test_split()\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "#test size = ???\n",
    "#random_state = ???\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Insert data it in an array \n",
    "blank_scores = pd.read_csv(\"MCAT_Data.csv\", header=1,usecols=range(3,3+4*6))\n",
    "\n",
    "\n",
    "blank_scores_array = blank_scores.values\n",
    "'''\n",
    "#Reshape them as a tensor of dimension : number of data points, number of blank exams, number of \"under exams\" + total score + days before exam \n",
    "blank_scores_tensor = blank_scores_array.reshape(blank_scores_array.shape[0],4,6)\n",
    "blank_scores_tensor = blank_scores_tensor[:,:,:3]\n",
    "\n",
    "X = np.squeeze(blank_scores_tensor,axis=2)\n",
    "print(X.shape)\n",
    "y = scores[\"Real Score\"].to_numpy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear' )\n",
    "clf.fit(X_train[:200], y_train[:200])\n",
    "\n",
    "#sanity check: look at how many data points are in train/test\n",
    "len(train_set)\n",
    "len(test_set)\n",
    "\n",
    "'''\n",
    "\n",
    "for i in range(4):\n",
    "    blank_scores = blank_scores.drop(columns=[\"Days Before Exam\"+str(i)])\n",
    "#blank_scores = blank_scores.drop(columns=[\"Days Before Exam.1\"])\n",
    "#    i+=1\n",
    "blank_scores.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee9310-adba-4961-945e-8499cfe357cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform checksum/hash sum OR cyclic rendunancy check (CRC) on data\n",
    "#how to do it???\n",
    "#see here: https://www.codeproject.com/Articles/1671/CRC32-Generating-a-checksum-for-a-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af13b459-b7e4-4d80-b906-a28455a1334e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#sanity check: preview test and training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      3\u001b[0m test_set\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "#sanity check: preview test and training data\n",
    "train_set.head()\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd3985-d8ec-46e6-986b-2ccd58ea7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform stratified shufflesplit cross-validator\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\n",
    "#compares random and stratified error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4fbcb-5d38-4732-ba5f-68c36f66a256",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3264128-74a0-43ab-8920-00dba5d700cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create scatter plot of data with alpha=???\n",
    "#add legends, titles, and color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d45b6b-5fc9-4a90-a653-6f533416cb21",
   "metadata": {},
   "source": [
    "## Visualize Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213876c-f1d2-48d3-a7f9-afbec1c4fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n",
    "\n",
    "#create scatter matrices displaying totals, medians.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf21199-73ee-488c-99ca-f43fe813d810",
   "metadata": {},
   "source": [
    "## Prepare Data for ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67668154-0634-4464-ae1c-fd64ff6c4e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop data labels\n",
    "\n",
    "#save labels in a separate variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30150f-e06e-4198-a69b-228677baa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that have negative values\n",
    "#                # days before exam > 180\n",
    "#                # no final MCAT score\n",
    "#                # exact duplicate values to another row\n",
    "\n",
    "# sanity check: preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d4e63-dc82-45c5-8aed-6c023d0d90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom attribute: variance between test scores (if multiple test scores)\n",
    "# NOTE: make sure variance is calculated between different tests, not between subsections of the same test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7c5ad-c7dc-4a7b-a0b6-8c52804abf5c",
   "metadata": {},
   "source": [
    "## Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55abb8-d778-47a2-8130-3ab4af306a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows you to easily apply a list of transforms and fit methods in a given order\n",
    "from sklearn.pipeline import Pipeline\n",
    "# standardizes features, which is a requirement for many ML estimators\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd3d7f-2eb1-4a9d-a750-d70fb1937656",
   "metadata": {},
   "source": [
    "# Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9dde2b-ecb0-4188-aece-a5f3d5133630",
   "metadata": {},
   "source": [
    "## Training and Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0a86f-9ca3-4a6b-91e1-a1e4d85a1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Explain the process of model validation\n",
    "# how did you split the data into training, validation and test sets\n",
    "# What are the sizes of each set and why did you make such design choice.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# initialize a linear regression object\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(\"DATA\", \"LABELS\")\n",
    "\n",
    "# sanity check: test out predictions and compare to labels\n",
    "print(lin_reg.predict(\"SOME DATA\"))\n",
    "print(list(\"SOME LABELS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22003fb7-b472-48ea-a212-43d1f5b4a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MCAT_predictions = lin_reg.predict(\"DATA\")\n",
    "lin_rmse = mean_squared_error(\"LABELS\", MCAT_predictions, squared=False)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971bf4d-76e4-4070-92b6-ba2c734d1847",
   "metadata": {},
   "source": [
    "## Evaluation with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee1601-8cdc-4a7a-9596-eee6bbc3f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, \"DATA\", \"LABELS\",\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
